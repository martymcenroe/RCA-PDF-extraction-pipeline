This Software Design Specification (SDS) outlines the architecture for **G-FIAT (Geological Forensic Image Analysis Toolkit)**. This system is designed to operationalize the forensic protocols defined in the research report, specifically targeting image reuse (cloning), geometric manipulation (rotation/scaling), and resampling artifacts (pixel shifting) in geological PDF reports.

### **1. System Overview**

* **System Name:** G-FIAT (Geological Forensic Image Analysis Toolkit)
* **Primary Objective:** To ingest PDF geological reports, extract image assets without altering their compression artifacts, and perform two parallel streams of analysis:
1. **Semantic Deduplication:** Detecting reused core photos across different depths or different well reports, even if rotated, cropped, or resized.
2. **Manipulation Detection:** identifying statistical anomalies (pixel shifting, splicing) inconsistent with raw camera sensor data.


* **Target Environment:** Python 3.10+ Linux/Windows environment; Containerized (Docker) for deployment.

---

### **2. System Architecture**

The system follows a pipeline architecture comprising four distinct stages: **Ingestion**, **fingerprinting**, **Analysis**, and **Reporting**.

#### **Module 1: The Ingestion Engine (Lossless Extraction)**

* **Goal:** Extract images from PDFs *exactly* as they exist in the file structure. Taking screenshots or converting pages to JPGs destroys forensic evidence (compression artifacts).
* **Core Library:** `PyMuPDF` (fitz) or `poppler-utils` (`pdfimages`).
* **Requirement:** The extractor must bypass the PDF rendering layer and access the raw binary stream of the image object (XObject).
* **Output:** A directory of raw image files (likely JPG, JBIG2, or TIFF) and a JSON manifest linking each image to its source page and location.

#### **Module 2: The Fingerprinting Engine**

* **Goal:** Convert raw pixels into mathematical signatures that resist manipulation.
* **Algorithms:**
* **Perceptual Hash (pHash):** For quick "exact match" filtering.
* **SIFT (Scale-Invariant Feature Transform):** The "nuclear option" for rotation/scale invariance. It identifies "keypoints" (distinctive textures like grain boundaries or vugs) that persist even if the image is rotated 30 degrees or shrunk by 50%.


* **Output:** A feature vector database (stored locally using SQLite or FAISS).

#### **Module 3: The Forensic Analysis Engine**

This is the core logic that tests the user's hypothesis.

* **Test A: The "Twin" Check (Duplicate Detection)**
* *Logic:* Compare SIFT descriptors of every image against every other image.
* *Threshold:* If >30% of keypoints match between Image A (Depth 9,000 ft) and Image B (Depth 9,050 ft), flag as a **Clone**.
* *Capability:* Detects "cookie-cutter" fraud where a sample is reused, rotated, and darkened.


* **Test B: The "Pixel Shift" Check (Resampling Detection)**
* *Logic:* Perform **Error Level Analysis (ELA)**. Re-compress the image at 95% JPEG quality and subtract the result from the original.
* *Threshold:* If a specific region (e.g., a "porous" patch) shows significantly higher error rates (brighter pixels) than the surrounding rock, flag as **Spliced/Manipulated**.
* *Frequency Analysis:* Run a 2D Fast Fourier Transform (FFT). If periodic spikes appear in the high-frequency spectrum, flag as **Resampled** (evidence of digital resizing/rotation).



#### **Module 4: Reporting & Visualization**

* **Goal:** Present evidence to a non-technical user (e.g., an auditor).
* **Output:** An HTML report showing:
* Side-by-side comparison of duplicates with matching keypoints connected by lines.
* The "ELA Map" overlay highlighting the manipulated regions.



---

### **3. Technical Stack & Implementation Details**

To implement this, you will need the following Python ecosystem:

| Component | Library/Tool | Purpose |
| --- | --- | --- |
| **PDF Handling** | `PyMuPDF` (fitz) | Extracts raw image streams without re-encoding. |
| **Computer Vision** | `OpenCV` (`cv2`) | Core image processing (reading, color space conversion). |
| **Feature Extraction** | `OpenCV` (SIFT) | Generates rotation-invariant keypoints (formerly patented, now free). |
| **Hashing** | `ImageHash` | Generates pHash for rapid pre-filtering. |
| **Vector Search** | `FAISS` (Facebook AI Similarity Search) | OPTIONAL: Essential if comparing against *thousands* of past reports (Big Data). |
| **Math/Signal** | `NumPy`, `SciPy` | FFT implementation for resampling detection. |
| **Visualization** | `Matplotlib` / `Pillow` | Generating ELA overlays and matching diagrams. |

---

### **4. Implementation Roadmap (Step-by-Step)**

#### **Phase 1: The "Twin" Finder (Proof of Concept)**

1. **Script Setup:** Create a Python script that accepts a single PDF path.
2. **Extraction:** Use `PyMuPDF` to iterate through pages, find `XObject` images, and save them to a temp folder.
3. **SIFT Matching:** Use `cv2.SIFT_create()` to generate descriptors for all extracted images.
4. **Brute Force Matcher:** Use `cv2.BFMatcher()` to compare all pairs.
5. **Output:** Print alerts: *"Warning: Image 4 on Page 2 matches Image 12 on Page 8 (98% similarity)."*

#### **Phase 2: The "Pixel Shift" Detector**

1. **ELA Function:** Implement a function that:
* Reads the extracted raw image.
* Saves a temporary copy at `quality=90`.
* Calculates `abs(original_pixel - temp_pixel)`.
* Scales the difference to be visible (e.g., multiply by 10).


2. **Integration:** Run this on all images flagged as "high porosity" or "critical interval."

#### **Phase 3: The "Cookie Cutter" Database (Scale Up)**

1. **Reference DB:** Create a folder of *historical* well reports (e.g., from NDIC).
2. **Ingest & Store:** Run the extraction on all of them and store their SIFT descriptors in a file-based database.
3. **Cross-Check:** When analyzing a *new* report (e.g., W20552), check its images not just against itself, but against this historical database. This catches fraud where a lab reuses a photo from a well drilled 5 years ago.

---

### **5. Immediate "To-Do" List for Implementation**

To start building this *today*, you need to execute the following:

1. **Acquire the "Ground Truth":** You need the *Technical Report* for Muller 1-21-16H (not just the admin PDF). Contact the North Dakota Industrial Commission (NDIC) or check their premium data portal for the **Core Analysis Report** or **Petrography Report**.
2. **Environment Setup:**
```bash
pip install pymupdf opencv-python-headless imagehash numpy scipy matplotlib

```


3. **Standardize "Valid" Images:** Geological reports contain logos, charts, and diagrams. You must write a filter (based on aspect ratio or color histogram) to ignore these and focus only on **rock photos** (which typically look like high-texture noise).
4. **Verification:** Run the tool on a known "clean" report first to calibrate the sensitivity of the SIFT matcher. If the threshold is too low, similar-looking sandstones will flag as false positives.

### **6. Sample Code Snippet (The "Twin" Logic)**

This snippet demonstrates the critical SIFT matching logic that defeats rotation/scaling attempts.

```python
import cv2
import fitz  # PyMuPDF

def check_for_twins(img_path1, img_path2):
    # 1. Load images
    img1 = cv2.imread(img_path1, cv2.IMREAD_GRAYSCALE)
    img2 = cv2.imread(img_path2, cv2.IMREAD_GRAYSCALE)

    # 2. Initialize SIFT detector
    sift = cv2.SIFT_create()

    # 3. Find keypoints and descriptors
    kp1, des1 = sift.detectAndCompute(img1, None)
    kp2, des2 = sift.detectAndCompute(img2, None)

    # 4. Match features using FLANN matcher (Fast Library for Approximate Nearest Neighbors)
    index_params = dict(algorithm=1, trees=5)
    search_params = dict(checks=50)
    flann = cv2.FlannBasedMatcher(index_params, search_params)
    
    matches = flann.knnMatch(des1, des2, k=2)

    # 5. Apply "Lowe's Ratio Test" to keep only strong matches
    good_matches =
    for m, n in matches:
        if m.distance < 0.7 * n.distance:
            good_matches.append(m)

    # 6. Scoring
    # If a significant number of features match, it's a clone, regardless of rotation
    if len(good_matches) > 50: 
        return True, len(good_matches)
    return False, len(good_matches)

```