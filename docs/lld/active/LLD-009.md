# 10009 - Feature: Data Analysis & Validation for Extracted Core Samples

## 1. Context & Goal
* **Issue:** #9
* **Objective:** Create a comprehensive data analysis script that validates extracted RCA data and generates summary statistics
* **Status:** Approved
* **Related Issues:** #6 (analytics format may be input)
* **Effort Estimate:** M (Medium)

### Open Questions
*Questions that need clarification before or during implementation. Remove when resolved.*

- [x] Should visualizations be optional (CLI flag) to avoid matplotlib dependency? **Decision: Yes, Fail Open if matplotlib missing**
- [ ] What is the expected depth range for W20552? (Estimated: 9,500-10,000 ft)
- [ ] Should validation include a "Data Quality Score" percentage?
- [ ] Move depth range thresholds to config file for extensibility?

## 2. Proposed Changes

*This section is the **source of truth** for implementation. Describe exactly what will be built.*

### 2.1 Files Changed

| File | Change Type | Description |
|------|-------------|-------------|
| `scripts/analyze_output.py` | Add | Main analysis script with CLI |
| `scripts/validators/structural.py` | Add | Structural validation functions |
| `scripts/validators/range.py` | Add | Range validation functions |
| `scripts/validators/consistency.py` | Add | Consistency validation functions |
| `scripts/analysis/statistics.py` | Add | Summary statistics generation |
| `scripts/analysis/visualizations.py` | Add | Matplotlib plotting functions |
| `data/output/analysis/.gitkeep` | Add | Ensure output directory exists |
| `tests/test_analyze_output.py` | Add | Unit tests for validation logic |
| `tests/fixtures/validation_fixtures.json` | Add | Fixture manifest for offline development |
| `tests/fixtures/valid_138_rows.csv` | Add | Valid test CSV |
| `tests/fixtures/corrupted_data.csv` | Add | Corrupted test CSV |

### 2.2 Offline Development Strategy

**Fixture Manifest:** Define a JSON manifest specifying the schema for test fixtures to allow validation logic development without the upstream extraction pipeline.

```json
// tests/fixtures/validation_fixtures.json
{
    "schema": {
        "required_columns": ["sample_number", "depth_feet", "permeability_air_md",
                            "permeability_klink_md", "porosity_ambient_pct", "porosity_ncs_pct",
                            "saturation_water_pct", "saturation_oil_pct", "saturation_total_pct",
                            "grain_density_gcc", "core_number"],
        "row_count": 138,
        "depth_range": [9500, 10000],
        "cores": [4, 5]
    },
    "fixtures": {
        "valid": "valid_138_rows.csv",
        "corrupted": "corrupted_data.csv",
        "out_of_range": "out_of_range_values.csv",
        "duplicate_samples": "duplicate_samples.csv"
    }
}
```

**Development Workflow:**
1. Create fixture CSV files matching the schema
2. Develop validation functions using fixtures - no extraction pipeline needed
3. Integration test with real extracted data as final step

### 2.3 Dependencies

*New packages, APIs, or services required.*

```toml
[project.optional-dependencies]
analysis = [
    "pandas>=2.0.0",
    "matplotlib>=3.7.0",
    "numpy>=1.24.0",
]
```

### 2.4 Data Structures

```python
# Pseudocode - NOT implementation

# Resource safety limit
MAX_VALIDATION_ROWS = 10000  # Prevent memory spikes on unexpectedly large datasets

@dataclass
class ValidationResult:
    check_name: str
    status: Literal["PASS", "WARN", "FAIL"]
    message: str
    details: list[str] | None = None

@dataclass
class AnalysisReport:
    structural_checks: list[ValidationResult]
    range_checks: list[ValidationResult]
    consistency_checks: list[ValidationResult]
    statistics: dict[str, Any]
    overall_status: Literal["PASS", "WARN", "FAIL"]
```

### 2.5 Function Signatures

```python
# scripts/analyze_output.py
def validate_output_path(output_path: Path, project_root: Path) -> Path:
    """Validate output path is within project worktree.

    Raises:
        ValueError: If path resolves outside project directory
    """
    ...

def check_matplotlib_available() -> bool:
    """Check if matplotlib is available for visualizations."""
    ...

# scripts/validators/structural.py
def check_row_count(df: pd.DataFrame, expected: int = 138, max_rows: int = MAX_VALIDATION_ROWS) -> ValidationResult:
    """Verify row count matches expected samples."""
    ...

def check_required_columns(df: pd.DataFrame, required: list[str]) -> ValidationResult:
    """Verify all required columns present."""
    ...

def check_duplicate_samples(df: pd.DataFrame) -> ValidationResult:
    """Check for duplicate sample numbers."""
    ...

# scripts/validators/range.py
def check_depth_range(df: pd.DataFrame, min_val: float, max_val: float) -> ValidationResult:
    """Verify depth values within expected range."""
    ...

def check_permeability_range(df: pd.DataFrame) -> ValidationResult:
    """Verify permeability values reasonable (flag > 100 md)."""
    ...

# scripts/validators/consistency.py
def check_depth_monotonic(df: pd.DataFrame) -> ValidationResult:
    """Verify depth monotonically increasing within each core."""
    ...

def check_porosity_consistency(df: pd.DataFrame) -> ValidationResult:
    """Verify NCS porosity <= ambient porosity."""
    ...
```

### 2.6 Logic Flow (Pseudocode)

```
1. Parse arguments (input_csv, --output-dir)
2. Validate output path is within project worktree
   - IF invalid: raise ValueError, exit 2
3. Load CSV into DataFrame
4. IF len(df) > MAX_VALIDATION_ROWS (10000):
   - Log warning, truncate to MAX_VALIDATION_ROWS
5. Run structural validation:
   - Row count == 138
   - Required columns present
   - No duplicate samples
   - Both cores represented
6. Run range validation:
   - Depth in 9,500-10,000 ft
   - Permeability 0-1,000 md (warn > 100)
   - Porosity 0-30%
   - Saturation 0-100%
7. Run consistency validation:
   - Depth monotonic per core
   - NCS porosity <= ambient
8. Generate summary statistics
9. Check matplotlib availability:
   - IF available: Generate visualizations, verify PNG files non-empty
   - IF missing: Log WARNING "matplotlib not installed - skipping visualizations"
   - (FAIL OPEN: Continue with text report only)
10. Write text report to output directory
11. Log validation summary to stdout for CI visibility
12. Exit with code: 0=PASS, 1=WARN, 2=FAIL
```

### 2.7 Technical Approach

* **Module:** `scripts/analyze_output.py` (entry point)
* **Pattern:** Validation pipeline with categorized checks
* **Key Decisions:**
  - Use pandas for data manipulation (optional dependency)
  - Matplotlib for visualizations (optional)
  - Structured validation results for clear reporting
  - Exit codes indicate severity (0/1/2)

## 3. Requirements

*What must be true when this is done. These become acceptance criteria.*

1. Script runs successfully on extracted CSV
2. Structural validation identifies row count, column count, duplicates
3. Range validation flags values outside expected bounds
4. Consistency validation catches depth ordering and porosity mismatches
5. Summary statistics generated with handling for special values
6. Four visualization plots generated and saved
7. Console report shows pass/warn/fail with actionable details
8. Text report saved to `data/output/analysis/validation_report.txt`
9. Script exits 0 for pass, 1 for warnings, 2 for failures

## 4. Alternatives Considered

| Option | Pros | Cons | Decision |
|--------|------|------|----------|
| Jupyter notebook | Interactive | Not scriptable for CI | **Rejected** |
| Standalone script | CI-friendly, automated | Less interactive | **Selected** |
| External validation tool | Mature | New dependency, learning curve | **Rejected** |

**Rationale:** Standalone script enables CI integration while remaining simple to run manually.

## 5. Data & Fixtures

### 5.1 Data Sources

| Attribute | Value |
|-----------|-------|
| Source | Extracted core_analysis.csv |
| Format | CSV |
| Size | 138 rows |
| Refresh | Per extraction run |
| Copyright/License | Assignment material |

### 5.2 Data Pipeline

```
core_analysis.csv ──validate──► ValidationResults ──report──► validation_report.txt
                                      │
                                      └──► visualizations/ (PNG files)
```

### 5.3 Test Fixtures

| Fixture | Source | Notes |
|---------|--------|-------|
| Valid 138-row CSV | Extracted | Normal case |
| Corrupted CSV | Generated | Test error detection |
| Out-of-range values | Generated | Test range validation |

### 5.4 Deployment Pipeline

Local script - no deployment needed.

## 6. Diagram

N/A - Validation pipeline adequately described in logic flow.

## 7. Security Considerations

| Concern | Mitigation | Status |
|---------|------------|--------|
| Local files only | No network access | Addressed |
| Read-only input | Write only to designated output dir | Addressed |
| Worktree scope | Validate output path within project directory | TODO |
| Memory safety | MAX_VALIDATION_ROWS = 10000 limit | Addressed |

**Fail Modes:**
- **Input missing/malformed:** Fail Closed - Exit 2 with clear error
- **Matplotlib missing:** Fail Open - Log warning, produce text report only
- **Output path outside worktree:** Fail Closed - Exit 2 with error

**Worktree Scope Requirement:**
Output path MUST be validated to reside within `data/output/analysis/` or the project worktree:
```python
def validate_output_path(output_path: Path, project_root: Path) -> Path:
    resolved = output_path.resolve()
    try:
        resolved.relative_to(project_root.resolve())
        return resolved
    except ValueError:
        raise ValueError(f"Output path outside project: {output_path}")
```

### 7.1 Logging Strategy

| Event | Level | Message Format |
|-------|-------|----------------|
| Validation start | INFO | `Validating {csv_path}` |
| Structural check | INFO | `Structural: {check_name} - {status}` |
| Range check | INFO | `Range: {check_name} - {status}` |
| Consistency check | INFO | `Consistency: {check_name} - {status}` |
| Matplotlib missing | WARNING | `matplotlib not installed - skipping visualizations` |
| Plot generated | DEBUG | `Generated plot: {filename}` |
| Validation complete | INFO | `Validation complete: {overall_status} ({n_pass}/{n_warn}/{n_fail})` |
| Report written | INFO | `Report written to {path}` |

## 8. Performance Considerations

| Metric | Budget | Approach |
|--------|--------|----------|
| Memory | < 200MB | Pandas DataFrame for 138 rows |
| Latency | < 30s | Sequential validation, parallel plots |

**Bottlenecks:** Matplotlib rendering may be slow; acceptable for analysis script.

## 9. Risks & Mitigations

| Risk | Impact | Likelihood | Mitigation |
|------|--------|------------|------------|
| Matplotlib not installed | Med | Med | Make visualizations optional |
| Range thresholds wrong | Low | Med | Configurable thresholds |
| Unexpected data format | Med | Low | Graceful error handling |

## 10. Verification & Testing

### 10.1 Test Scenarios

| ID | Scenario | Type | Input | Expected Output | Pass Criteria |
|----|----------|------|-------|-----------------|---------------|
| 010 | Valid data passes | Auto | 138-row CSV | Exit 0, PASS | All checks pass |
| 020 | Wrong row count | Auto | 100-row CSV | Exit 2, FAIL | Structural fail |
| 030 | Out-of-range depth | Auto | depth=20000 | Exit 1, WARN | Range warning |
| 040 | Duplicate samples | Auto | 2x sample "6-1" | Exit 2, FAIL | Structural fail |
| 050 | Missing file | Auto | nonexistent.csv | Exit 2, error msg | Clear error |
| 060 | Statistics generated | Auto | Valid CSV | Stats in report | Values present |
| 070 | Matplotlib missing | Auto | Mock no matplotlib | Exit 0, warning logged | Text report only |
| 080 | Path outside worktree | Auto | /tmp/output | Exit 2, error | Path rejected |
| 090 | Large file (>10k rows) | Auto | 15000-row CSV | Warning, truncated | MAX_ROWS applied |
| 100 | PNG files valid | Auto | Generated plots | Non-zero size, valid header | PNG integrity |

### 10.2 Test Commands

```bash
# Run on valid data
python scripts/analyze_output.py data/output/spec/core_analysis.csv

# Run on test fixtures
python scripts/analyze_output.py tests/fixtures/corrupted_core_data.csv

# Run with output directory
python scripts/analyze_output.py data/output/spec/core_analysis.csv --output data/output/analysis/
```

### 10.3 Manual Tests (Only If Unavoidable)

| ID | Scenario | Why Not Automated | Steps |
|----|----------|-------------------|-------|
| 110 | Visual plot review | Requires human judgment | Compare plots against PDF figures |

**Automated PNG Validation (Scenario 100):**
```python
def test_png_files_valid():
    """Verify generated PNG files are non-zero and have valid headers."""
    import struct
    PNG_HEADER = b'\x89PNG\r\n\x1a\n'

    for png_file in output_dir.glob("*.png"):
        assert png_file.stat().st_size > 0, f"Empty PNG: {png_file}"
        with open(png_file, 'rb') as f:
            header = f.read(8)
            assert header == PNG_HEADER, f"Invalid PNG header: {png_file}"
```

## 11. Definition of Done

### Code
- [ ] Implementation complete and linted
- [ ] Validation modules implemented
- [ ] Visualization functions implemented

### Tests
- [ ] All test scenarios pass
- [ ] Test coverage meets threshold

### Documentation
- [ ] LLD updated with any deviations
- [ ] Implementation Report completed
- [ ] README updated with usage

### Review
- [ ] Code review completed
- [ ] Manual plot review completed

---

## Appendix: Review Log

*Track all review feedback with timestamps and implementation status.*

### Gemini 3 Pro Review #1 (REVISE)

**Timestamp:** 2026-01-29
**Reviewer:** Gemini 3 Pro (Senior Software Architect & AI Governance Lead)
**Verdict:** REVISE

#### Comments

| ID | Comment | Implemented? |
|----|---------|--------------|
| G1.1 | "Unbounded Loop Execution (BLOCKING): Add MAX_VALIDATION_ROWS limit" | YES - Added MAX_VALIDATION_ROWS = 10000 in Section 2.4 |
| G1.2 | "Worktree Scope (CRITICAL): Validate output path within project worktree" | YES - Added validate_output_path() in Section 2.5 and 7 |
| G1.3 | "Fail-Safe Strategy (Dependency Missing) (BLOCKING): Define behavior when matplotlib missing" | YES - Fail Open with warning in Section 2.6 and 7 |
| G1.4 | "Offline Development (CRITICAL): Define JSON/CSV schema for fixtures" | YES - Added Section 2.2 with validation_fixtures.json |
| G1.5 | "Logging Strategy: Use standard logging for CI visibility" | YES - Added Section 7.1 |
| G1.6 | "Test Integrity (Visualizations): Check PNG files non-zero/valid" | YES - Added Scenario 100 with PNG validation code |
| G1.7 | "Configurable thresholds for depth range" | DEFERRED - Added to Open Questions |
| G1.8 | "Use vectorized pandas operations" | NOTED - Best practice for implementation |

---

### Gemini 3 Pro Review #2 (APPROVED)

**Timestamp:** 2026-01-30
**Reviewer:** Gemini 3 Pro (Senior Software Architect & AI Governance Lead)
**Verdict:** APPROVED

#### Comments

| ID | Comment | Implemented? |
|----|---------|--------------|
| G2.1 | "Implement Data Quality Score (passed/total * 100) in text report" | NOTED - Recommendation for implementation |
| G2.2 | "Use pandas vectorization for range/consistency checks" | NOTED - Best practice for implementation |

### Review Summary

| Review | Date | Verdict | Key Issue |
|--------|------|---------|-----------|
| Gemini 3 Pro #1 | 2026-01-29 | REVISE | MAX_ROWS, worktree scope, matplotlib handling |
| Gemini 3 Pro #2 | 2026-01-30 | APPROVED | No blocking issues |

**Final Status:** APPROVED
